## LLM Prompts Used

1. How does a sitemap crawler work in a backend system?

2. What is the difference between queue-based processing and direct API processing?

3. How should pending, success, and failed states work in a crawler?

4. What happens if a worker crashes while jobs are still in the queue?

5. How does retry and backoff work in BullMQ?

6. Why can a page have more incoming links than outgoing links?

7. How can we avoid crawling the same URL multiple times?
